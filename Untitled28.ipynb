{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457abbe4-5ace-497e-b170-7f827e22129a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "# Define example descriptions for each question\n",
    "question_descriptions = {\n",
    "    \"problem_domain\": \"e.g. 'web development', 'data science', 'machine learning'\",\n",
    "    \"languages\": \"e.g. 'Python', 'JavaScript', 'Java'\",\n",
    "    \"tasks\": \"e.g. 'Write a function that sorts a list of integers', 'Build a web app that displays data from an API'\",\n",
    "    \"constraints\": \"e.g. 'The code must be compatible with Python 3.6+', 'The code must run in a low-memory environment'\",\n",
    "    \"sources\": \"e.g. 'Stack Overflow', 'GitHub', 'online courses'\",\n",
    "    \"search_query\": \"e.g. 'Python code example to sort a list of integers'\",\n",
    "    \"preprocessing\": \"e.g. 'Remove comments and whitespace', 'Extract only the relevant code snippets'\",\n",
    "    \"framework\": \"e.g. 'TensorFlow', 'PyTorch', 'scikit-learn'\",\n",
    "    \"hyperparameters\": \"e.g. '{'learning_rate': 0.01, 'batch_size': 32}', '{'num_layers': 2, 'hidden_size': 256}'\",\n",
    "    \"evaluation\": \"e.g. 'Manually evaluate the generated code for correctness and efficiency', 'Use a test suite to evaluate the performance of the generated code'\",\n",
    "}\n",
    "\n",
    "# Define a function to prompt the user to answer each question manually\n",
    "def manual_prompt():\n",
    "    print(\"Please answer the following questions to define the specific use case for the code generation tool:\")\n",
    "    previous_answers = []\n",
    "    for question in question_descriptions:\n",
    "        answer = input(f\"{question.capitalize()}: ({question_descriptions[question]}) \")\n",
    "        previous_answers.append(answer)\n",
    "    return previous_answers\n",
    "\n",
    "# Define a function to automatically prompt the user to answer each question using an automated Q&A approach\n",
    "def automated_prompt():\n",
    "    print(\"Please think of a problem to solve using code, and I will ask you some questions to help define the specific use case:\")\n",
    "    previous_answers = []\n",
    "    relevant_questions = list(question_descriptions.keys())\n",
    "    while len(relevant_questions) > 0:\n",
    "        question = np.random.choice(relevant_questions)\n",
    "        answer = input(f\"{question_descriptions[question]}? \")\n",
    "        prediction = predict_answer(answer, previous_answers)\n",
    "        previous_answers.append(prediction)\n",
    "        print(f\"My guess: {prediction}\")\n",
    "        if prediction == \"N/A\":\n",
    "            remove_question = input(f\"Sorry, I couldn't guess the answer to this question. Would you like to remove it? (Y/N) \")\n",
    "            if remove_question.upper() == \"Y\":\n",
    "                relevant_questions.remove(question)\n",
    "        else:\n",
    "            relevant_questions.remove(question)\n",
    "    return previous_answers\n",
    "\n",
    "# Define a function to preprocess the example responses\n",
    "def preprocess_responses(responses):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(responses)\n",
    "    return X, vectorizer\n",
    "\n",
    "# Define a function to predict the most likely answer to a question based on the user's input\n",
    "def predict_answer(user_input, previous_answers):\n",
    "    if user_input:\n",
    "        # If the user has provided an answer, use it to predict the most likely answer\n",
    "        X_test = vectorizer.transform([user_input])\n",
    "        prediction = clf.predict(X_test)[0]\n",
    "    else\n",
    "        # If the user has not provided an answer, use the previous answers to make a prediction\n",
    "        X_test = vectorizer.transform(previous_answers)\n",
    "        predictions = clf.predict_proba(X_test)\n",
    "        prediction = responses_df[\"answer\"][np.argmax(predictions[:,1])]\n",
    "    return prediction\n",
    "\n",
    "# Load the example responses for each question\n",
    "responses_df = pd.read_csv(\"responses.csv\")\n",
    "X, vectorizer = preprocess_responses(responses_df[\"response\"])\n",
    "\n",
    "# Train a decision tree classifier to predict the most likely answer to each question\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, responses_df[\"answer\"])\n",
    "\n",
    "# Prompt the user to choose between manual and automated prompts\n",
    "prompt_type = input(\"Would you like to define the use case manually (M) or using an automated Q&A (Q)? \")\n",
    "\n",
    "# Call the appropriate prompt function based on the user's choice\n",
    "if prompt_type.upper() == \"M\":\n",
    "    previous_answers = manual_prompt()\n",
    "else:\n",
    "    previous_answers = automated_prompt()\n",
    "\n",
    "# Define the input text to be used as a prompt for the language model\n",
    "input_text = f\"Generate code to solve the following problem:\\n\\n\"\n",
    "input_text += f\"{previous_answers[2]} using {previous_answers[1]}. {previous_answers[3]}\\n\"\n",
    "\n",
    "# Use the data scraping tool to search for relevant code examples\n",
    "search_results = requests.get(f\"https://www.google.com/search?q={previous_answers[5]}&num=10\")\n",
    "soup = BeautifulSoup(search_results.text, \"html.parser\")\n",
    "code_snippets = []\n",
    "for link in soup.find_all(\"a\"):\n",
    "    url = link.get(\"href\")\n",
    "    if url.startswith(\"/url?q=\") and not url.startswith(\"/url?q=https://www.google.com\"):\n",
    "        url = url.split(\"/url?q=\")[1].split(\"&\")[0]\n",
    "        code_snippets.append(requests.get(url).text)\n",
    "\n",
    "# Fine-tune the language model on the scraped code snippets\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci-codex\",\n",
    "    prompt=input_text,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    "    fine_tune_model=previous_answers[8],\n",
    "    fine_tune_dataset=code_snippets,\n",
    "    hyperparameters=previous_answers[9],\n",
    ")\n",
    "\n",
    "# Extract the generated code from the OpenAI response\n",
    "generated_code = response.choices[0].text\n",
    "\n",
    "# Clean up the generated code\n",
    "generated_code = re.sub(r\"\\n{3,}\", \"\\n\\n\", generated_code)  # Remove excess blank lines\n",
    "generated_code = generated_code.strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "# Print the generated code\n",
    "print(\"Generated code:\\n\")\n",
    "print(generated_code)\n",
    "\n",
    "# Write the generated code to a file\n",
    "with open(\"generated_code.py\", \"w\") as f:\n",
    "    f.write(generated_code)\n",
    "\n",
    "# Execute the generated code\n",
    "print(\"\\nExecuting generated code...\\n\")\n",
    "exec(generated_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f9ab7-7ee0-48e8-b5e2-05d90db278de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def preprocess_responses(responses):\n",
    "    \"\"\"\n",
    "    Preprocess the text responses for use in the decision tree classifier.\n",
    "    \"\"\"\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(responses)\n",
    "    return X, vectorizer\n",
    "\n",
    "def manual_prompt():\n",
    "    \"\"\"\n",
    "    Manually prompt the user to provide answers to each question.\n",
    "    \"\"\"\n",
    "    # Load the example questions\n",
    "    questions_df = pd.read_csv(\"questions.csv\")\n",
    "    questions = questions_df[\"question\"].tolist()\n",
    "\n",
    "    # Prompt the user to provide an answer for each question\n",
    "    previous_answers = []\n",
    "    for question in questions:\n",
    "        answer = input(f\"{question} \")\n",
    "        previous_answers.append(answer)\n",
    "    return previous_answers\n",
    "\n",
    "def automated_prompt():\n",
    "    \"\"\"\n",
    "    Use a decision tree classifier to automatically prompt the user to provide answers to a random selection of questions.\n",
    "    \"\"\"\n",
    "    # Load the example responses for each question\n",
    "    responses_df = pd.read_csv(\"responses.csv\")\n",
    "    X, vectorizer = preprocess_responses(responses_df[\"response\"])\n",
    "\n",
    "    # Train a decision tree classifier to predict the most likely answer to each question\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, responses_df[\"answer\"])\n",
    "\n",
    "    # Define the list of questions\n",
    "    questions_df = pd.read_csv(\"questions.csv\")\n",
    "    questions = questions_df[\"question\"].tolist()\n",
    "\n",
    "    # Prompt the user to provide answers to a random selection of questions\n",
    "    previous_answers = []\n",
    "    for i in range(5):\n",
    "        question = clf.predict(vectorizer.transform([questions[i]]))[0]\n",
    "        answer = input(f\"{question} \")\n",
    "        previous_answers.append(answer)\n",
    "\n",
    "    return previous_answers\n",
    "\n",
    "# Define a function to search for relevant code examples\n",
    "def search_code_examples(query):\n",
    "    \"\"\"\n",
    "    Use a data scraping tool to search for relevant code examples.\n",
    "    \"\"\"\n",
    "    search_results = requests.get(f\"https://www.google.com/search?q={query}&num=10\")\n",
    "    soup = BeautifulSoup(search_results.text, \"html.parser\")\n",
    "    code_snippets = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        url = link.get(\"href\")\n",
    "        if url.startswith(\"/url?q=\") and not url.startswith(\"/url?q=https://www.google.com\"):\n",
    "            url = url.split(\"/url?q=\")[1].split(\"&\")[0]\n",
    "            code_snippets.append(requests.get(url).text)\n",
    "    return code_snippets\n",
    "\n",
    "# Define a function to generate the code\n",
    "def generate_code(previous_answers):\n",
    "    \"\"\"\n",
    "    Generate the code based on the user's input and the scraped code snippets.\n",
    "    \"\"\"\n",
    "    # Define the input text to be used as a prompt for the language model\n",
    "    input_text = f\"Generate code to solve the following problem:\\n\\n\"\n",
    "    input_text += f\"{previous_answers[2]} using {previous_answers[1]}. {previous_answers[3]}\\n\"\n",
    "\n",
    "    # Search for relevant code examples\n",
    "    code_snippets = search_code_examples(previous_answers[5])\n",
    "\n",
    "    # Fine-tune the language model on the scraped code snippets\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci-codex\",\n",
    "        prompt=input_text,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "        fine_tune_model=previous_answers[8],\n",
    "        fine_tune_dataset=code_snippets,\n",
    "        hyperparameters=previous_answers[9],\n",
    "    )\n",
    "\n",
    "        # Extract the generated code from the OpenAI response\n",
    "    generated_code = response.choices[0].text.strip()\n",
    "\n",
    "    # Catch any syntax or runtime errors in the generated code\n",
    "    try:\n",
    "        exec(generated_code)\n",
    "    except SyntaxError as e:\n",
    "        print(\"Syntax error:\", e)\n",
    "        print(\"Please modify the input text and try again.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Runtime error:\", e)\n",
    "        print(\"Please modify the input text and try again.\")\n",
    "        return None\n",
    "\n",
    "    # Return the generated code\n",
    "    return generated_code\n",
    "\n",
    "# Define the main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prompt the user to provide input and generate code based on the user's responses.\n",
    "    \"\"\"\n",
    "    # Prompt the user to provide input manually or automatically\n",
    "    prompt_choice = input(\"Would you like to manually answer questions or have them generated automatically? \")\n",
    "    if prompt_choice.lower() == \"manual\":\n",
    "        previous_answers = manual_prompt()\n",
    "    elif prompt_choice.lower() == \"automatic\":\n",
    "        previous_answers = automated_prompt()\n",
    "\n",
    "    # Generate the code\n",
    "    generated_code = generate_code(previous_answers)\n",
    "    if generated_code:\n",
    "        print(\"Generated code:\")\n",
    "        print(generated_code)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
