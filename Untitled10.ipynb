{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a731837-b548-45d9-8843-e02320521de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(predictions, y_test):\n",
    "mse = np.mean((predictions-y_test)**2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "Load new data\n",
    "\n",
    "def load_data():\n",
    "df = pd.read_csv(\"crypto_data.csv\")\n",
    "return df\n",
    "Continuously retrain and make predictions\n",
    "\n",
    "while True:\n",
    "try:\n",
    "# Load new data\n",
    "df = load_data()\n",
    "\n",
    "python\n",
    "\n",
    "    # Prepare new data for model\n",
    "    X_train, y_train, X_test, y_test = prepare_data(df)\n",
    "    \n",
    "    # Train the best model\n",
    "    best_model = train_best_model(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = make_predictions(best_model, X_test)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    evaluate_performance(predictions, y_test)\n",
    "    \n",
    "    # Sleep for a period of time before retraining the model\n",
    "    time.sleep(3600)  # sleep for 1 hour\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    time.sleep(3600)  # sleep for 1 hour\n",
    "    \n",
    "    # End the loop\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"crypto_data.csv\")\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    df = df.dropna()\n",
    "    df = df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    df = scaler.fit_transform(df)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data = df[:int(df.shape[0]*0.8)]\n",
    "    test_data = df[int(df.shape[0]*0.8):]\n",
    "\n",
    "    X_train, y_train = train_data[:,:-1], train_data[:,-1]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test, y_test = test_data[:,:-1], test_data[:,-1]\n",
    "    X_test = np.reshape( \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "# Create the csv file\n",
    "data = {'Close': [10, 20, 30, 40, 50],\n",
    "        'Volume': [100, 200, 300, 400, 500],\n",
    "        'Market Cap': [1000, 2000, 3000, 4000, 5000],\n",
    "        'Open': [5, 15, 25, 35, 45],\n",
    "        'High': [15, 25, 35, 45, 55],\n",
    "        'Low': [5, 10, 15, 20, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('crypto_data.csv', index=False)\n",
    "\n",
    "def train_best_model(df,X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_best_model(X_train, y_train):\n",
    "    best_model = create_model(optimizer=grid_result.best_params_['optimizer'], activation=grid_result.best_params_['activation'])\n",
    "    best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "    return best_model\n",
    "\n",
    "def make_predictions(best_model, X_test):\n",
    "    predictions = best_model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def evaluate_performance(predictions, y_test):\n",
    "    mse = np.mean((predictions-y_test)**2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Load new data\n",
    "        df = load_data()\n",
    "\n",
    "        # Prepare new data for model\n",
    "        X_train, y_train, XX_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_best_model(X_train, y_train):\n",
    "    best_model = create_model(optimizer=grid_result.best_params_['optimizer'],\n",
    "                              activation=grid_result.best_params_['activation'])\n",
    "    best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "    return best_model\n",
    "\n",
    "def make_predictions(best_model, X_test):\n",
    "    predictions = best_model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def evaluate_performance(predictions, y_test):\n",
    "    mse = np.mean((predictions-y_test)**2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Load new data\n",
    "        df = load_data()\n",
    "\n",
    "        # Prepare new data for model\n",
    "        X_train, y_X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_best_model(X_train, y_train):\n",
    "    best_model = create_model(optimizer=grid_result.best_params_['optimizer'],\n",
    "                              activation=grid_result.best_params_['activation'])\n",
    "    best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "    return best_model\n",
    "\n",
    "def make_predictions(best_model, X_test):\n",
    "    predictions = best_model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def evaluate_performance(predictions, y_test):\n",
    "    mse = np.mean((predictions-y_test)**2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Load new data\n",
    "        df = load_data()\n",
    "\n",
    "        # Prepare new data for model\n",
    "        X_train, y_ scaler, best_model):\n",
    "    # Load and preprocess data\n",
    "    df = df.dropna()\n",
    "    df = df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "    df = scaler.fit_transform(df)\n",
    "\n",
    "    # Define training and test sets\n",
    "    train_data = df[:int(df.shape[0]*0.8)]\n",
    "    test_data = df[int(df.shape[0]*0.8):]\n",
    "\n",
    "    # Prepare data for model\n",
    "    X_train, y_train = train_data[:,:-1], train_data[:,-1]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test, y_test = test_data[:,:-1], test_data[:,-1]\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Train the model\n",
    "    best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = best_model.predict(X_test)\n",
    "    mse = np.mean((predictions-y_test)**2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"crypto_data.csv\")\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    df = df.dropna()\n",
    "    df = df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    df = scaler.fit_transform(df)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data = df[:int(df.shape[0]*0.8)]\n",
    "    test_data = df[int(df.shape[0]*0.8):]\n",
    "\n",
    "    X_train, y_train = train_data[:,:-1], train_data["
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
