{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883654ce-d54a-49e1-a18a-62f23120f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create the csv file\n",
    "data = {'Close': [10, 20, 30, 40, 50],\n",
    "'Volume': [100, 200, 300, 400, 500],\n",
    "'Market Cap': [1000, 2000, 3000, 4000, 5000],\n",
    "'Open': [5, 15, 25, 35, 45],\n",
    "'High': [15, 25, 35, 45, 55],\n",
    "'Low': [5, 10, 15, 20, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('crypto_data.csv', index=False)\n",
    "\n",
    "#Load the csv file\n",
    "df = pd.read_csv(\"crypto_data.csv\")\n",
    "\n",
    "#Load and preprocess data\n",
    "df = pd.read_csv(\"crypto_data.csv\")\n",
    "df = df.dropna()\n",
    "df = df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "#Define training and test sets\n",
    "train_data = df[:int(df.shape[0]*0.8)]\n",
    "test_data = df[int(df.shape[0]*0.8):]\n",
    "\n",
    "#Prepare data for model\n",
    "X_train, y_train = train_data[:,:-1], train_data[:,-1]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test, y_test = test_data[:,:-1], test_data[:,-1]\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#Define the model\n",
    "def create_model(optimizer='adam', activation='relu'):\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=5, activation=activation, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=activation))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "return model\n",
    "\n",
    "#Perform hyperparameter tuning\n",
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=32, verbose=0)\n",
    "param_grid = dict(optimizer=['adam', 'rmsprop'], activation=['relu', 'tanh'])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "#Use the best hyperparameters\n",
    "best_model = create_model(optimizer=grid_result.best_params_['optimizer'], activation=grid_result.best_params_['activation'])\n",
    "best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "#Make predictions on test data\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "#Evaluate model performance\n",
    "mse = np.mean((predictions-y_test)**2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "#Add the code to run the script continuously\n",
    "import time\n",
    "while True:\n",
    "try:\n",
    "\n",
    "    # Load new data\n",
    "new_df = pd.read_csv(\"new_crypto_data.csv\")\n",
    "\n",
    "python\n",
    "\n",
    "# Preprocess new data\n",
    "new_df = new_df.dropna()\n",
    "new_df = new_df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "new_df = scaler.transform(new_df)\n",
    "\n",
    "# Split new data into training and test sets\n",
    "new_train_data = new_df[:int(new_df.shape[0]*0.8)]\n",
    "new_test_data = new_df[int(new_df.shape[0]*0.8):]\n",
    "\n",
    "# Prepare new data for model\n",
    "new_X_train, new_y_train = new_train_data[:,:-1], new_train_data[:,-1]\n",
    "new_X_train = np.reshape(new_X_train, (new_X_train.shape[0], new_X_train.shape[1], 1))\n",
    "new_X_test, new_y_test = new_test_data[:,:-1], new_test_data[:,-1]\n",
    "new_X_test = np.reshape(new_X_test, (new_X_test.shape[0], new_X_test.shape[1], 1))\n",
    "\n",
    "# Retrain the model\n",
    "best_model.fit(new_X_train, new_y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Make predictions on new test data\n",
    "new_predictions = best_model.predict(new_X_test)\n",
    "\n",
    "# Evaluate model performance on new test data\n",
    "new_mse = np.mean((new_predictions-new_y_test)**2)\n",
    "print(\"Mean Squared Error:\", new_mse)\n",
    "\n",
    "# Save the updated model\n",
    "best_model.save(\"best_model.h5\")\n",
    "\n",
    "# Sleep for a period of time before retraining the model\n",
    "import time\n",
    "sleep_time = 60 * 60 * 24 # Sleep for 24 hours\n",
    "time.sleep(sleep_time)\n",
    "\n",
    "# Retrain the model with updated data\n",
    "df = pd.read_csv(\"crypto_data.csv\")\n",
    "\n",
    "# Load the updated data\n",
    "df = df.dropna()\n",
    "df = df[[\"Close\", \"Volume\", \"Market Cap\", \"Open\", \"High\", \"Low\"]]\n",
    "df = scaler.transform(df)\n",
    "\n",
    "# Preprocess the data using the MinMaxScaler\n",
    "train_data = df[:int(df.shape[0]*0.8)] # Split the data into training and test sets\n",
    "test_data = df[int(df.shape[0]*0.8):]\n",
    "X_train, y_train = train_data[:,:-1], train_data[:,-1]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
